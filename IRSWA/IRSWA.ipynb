{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "LJsG4WWFdB8_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from joblib import dump\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"Incident_dataset.csv\")\n",
        "y = df[\"label\"]"
      ],
      "metadata": {
        "id": "FLHAkAJxd1ap"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load SBERT (MiniLM)\n",
        "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Generate SBERT embeddings\n",
        "print(\"Generating SBERT embeddings...\")\n",
        "sbert_embeddings = sbert_model.encode(df[\"message\"].tolist(), convert_to_numpy=True)\n",
        "print(\"SBERT embedding shape:\", sbert_embeddings.shape)\n",
        "\n",
        "# Generate TF-IDF features\n",
        "print(\"Generating TF-IDF features...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=200)\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(df[\"message\"]).toarray()\n",
        "print(\"TF-IDF shape:\", tfidf_features.shape)\n",
        "\n",
        "# Save TF-IDF vectorizer\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "dump(tfidf_vectorizer, \"models/tfidf_vectorizer.joblib\")\n",
        "print(\"TF-IDF vectorizer saved to models/tfidf_vectorizer.joblib\")\n",
        "\n",
        "# Combine SBERT and TF-IDF\n",
        "X = np.concatenate((sbert_embeddings, tfidf_features), axis=1)\n",
        "print(\"Final feature shape:\", X.shape)\n",
        "\n",
        "# Optionally save X and y for later use\n",
        "dump(X, \"models/features_X.joblib\")\n",
        "dump(y, \"models/labels_y.joblib\")\n",
        "print(\"Features and labels saved.\")\n"
      ],
      "metadata": {
        "id": "01aAcogZd1cz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93862368-4910-4679-e3be-e1f895d5e6ea"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating SBERT embeddings...\n",
            "SBERT embedding shape: (15000, 384)\n",
            "Generating TF-IDF features...\n",
            "TF-IDF shape: (15000, 200)\n",
            "TF-IDF vectorizer saved to models/tfidf_vectorizer.joblib\n",
            "Final feature shape: (15000, 584)\n",
            "Features and labels saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "y_raw = df[\"label\"].values\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y_raw)\n",
        "joblib.dump(label_encoder, \"models/label_encoder.joblib\")"
      ],
      "metadata": {
        "id": "7WcwFIMGd1fG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af55d17-fc21-4a0f-cac5-a165e1d0a758"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models/label_encoder.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HE7AcMzLd1hb"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "joblib.dump(rf, \"models/rf_classifier.joblib\")"
      ],
      "metadata": {
        "id": "3A9cSbUHd77W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd1ef50-0bd3-4b81-c8f5-941c69e049db"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models/rf_classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train Logistic Regression\n",
        "print(\"Training Logistic Regression...\")\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "joblib.dump(lr, \"models/lr_classifier.joblib\")"
      ],
      "metadata": {
        "id": "tRybea2xd79v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2035ab70-333d-4673-9af5-d01e23c80fcb"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models/lr_classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train XGBoost\n",
        "print(\"Training XGBoost...\")\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb.fit(X_train, y_train)\n",
        "joblib.dump(xgb, \"models/xgb_classifier.joblib\")"
      ],
      "metadata": {
        "id": "BcCZvrbad8AP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3854032f-ca74-44a9-f1c1-a74af36e6d26"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:25:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models/xgb_classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Train ANN\n",
        "print(\"Training ANN...\")\n",
        "y_cat = to_categorical(y)\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "ann = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(y_cat.shape[1], activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "jeIaXcapd1je",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee0310e1-7a03-4320-88d3-c87bd6c1a266"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ANN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "ann.fit(X_train, y_train_cat, epochs=30, batch_size=64, validation_data=(X_test, y_test_cat))\n",
        "ann.save(\"models/ann_model.h5\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "id": "qOC9X60PesLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7560a8d8-e167-4f7f-ef4d-2a3a28a96f60"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8383 - loss: 0.9765 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
            "Epoch 2/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 2.0940e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 7.6578e-05\n",
            "Epoch 4/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1369e-04 - val_accuracy: 1.0000 - val_loss: 3.6473e-05\n",
            "Epoch 5/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4732e-04 - val_accuracy: 1.0000 - val_loss: 2.0330e-05\n",
            "Epoch 6/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8832e-04 - val_accuracy: 1.0000 - val_loss: 1.2124e-05\n",
            "Epoch 7/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9681e-04 - val_accuracy: 1.0000 - val_loss: 9.4818e-06\n",
            "Epoch 8/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.6960e-04 - val_accuracy: 1.0000 - val_loss: 5.5623e-06\n",
            "Epoch 9/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.6101e-05 - val_accuracy: 1.0000 - val_loss: 3.8512e-06\n",
            "Epoch 10/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.2335e-05 - val_accuracy: 1.0000 - val_loss: 2.7609e-06\n",
            "Epoch 11/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.3152e-05 - val_accuracy: 1.0000 - val_loss: 2.0451e-06\n",
            "Epoch 12/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.2686e-05 - val_accuracy: 1.0000 - val_loss: 1.5389e-06\n",
            "Epoch 13/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2492e-05 - val_accuracy: 1.0000 - val_loss: 1.4717e-06\n",
            "Epoch 14/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0159e-05 - val_accuracy: 1.0000 - val_loss: 9.5049e-07\n",
            "Epoch 15/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1914e-05 - val_accuracy: 1.0000 - val_loss: 6.9884e-07\n",
            "Epoch 16/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8884e-05 - val_accuracy: 1.0000 - val_loss: 6.6721e-07\n",
            "Epoch 17/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0255e-05 - val_accuracy: 1.0000 - val_loss: 3.9641e-07\n",
            "Epoch 18/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0504e-05 - val_accuracy: 1.0000 - val_loss: 3.1487e-07\n",
            "Epoch 19/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0265e-05 - val_accuracy: 1.0000 - val_loss: 2.4132e-07\n",
            "Epoch 20/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5524e-05 - val_accuracy: 1.0000 - val_loss: 1.9030e-07\n",
            "Epoch 21/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7128e-05 - val_accuracy: 1.0000 - val_loss: 1.5684e-07\n",
            "Epoch 22/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2217e-05 - val_accuracy: 1.0000 - val_loss: 1.1472e-07\n",
            "Epoch 23/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3582e-05 - val_accuracy: 1.0000 - val_loss: 8.2691e-08\n",
            "Epoch 24/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0446e-05 - val_accuracy: 1.0000 - val_loss: 6.8347e-08\n",
            "Epoch 25/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.9616e-06 - val_accuracy: 1.0000 - val_loss: 4.7525e-08\n",
            "Epoch 26/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.3639e-06 - val_accuracy: 1.0000 - val_loss: 4.0968e-08\n",
            "Epoch 27/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1627e-05 - val_accuracy: 1.0000 - val_loss: 6.7552e-08\n",
            "Epoch 28/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.1796e-06 - val_accuracy: 1.0000 - val_loss: 3.3021e-08\n",
            "Epoch 29/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4919e-06 - val_accuracy: 1.0000 - val_loss: 1.7921e-08\n",
            "Epoch 30/30\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9651e-06 - val_accuracy: 1.0000 - val_loss: 1.5616e-08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n"
          ]
        }
      ]
    }
  ]
}